process {
	executor = 'slurm'
	clusterOptions = '--job-name=nepal --account=nn9305k --mem-per-cpu=4700M'
	queueSize = 24
	maxRetries = 4
	errorStrategy='retry'

	time = { 2.h * task.attempt }

	withLabel: tiny {
		cpus = { 1 * task.attempt}
		time = { 1.h * task.attempt}
	}

	withLabel: medium {
		cpus = { 8 * task.attempt}
		time = { 4.h * task.attempt}
	}

	withLabel: heavy {
		cpus = { 20 * task.attempt}
		time = { 12.h * task.attempt}
	}

    withLabel: gpu {
		time = { 80.h * task.attempt} // big datasets
		//time = { 12.h * task.attempt} // small datasets
		clusterOptions = '--job-name=nepal_G --account=nn9305k --partition=accel --gpus-per-node=1 --mem=64G'
	}

	withLabel: gpu_A100 {
		time = { 80.h * task.attempt} // big datasets
		//time = { 12.h * task.attempt} // small datasets
		clusterOptions = '--job-name=nepal_G --account=nn9305k --partition=a100 --gpus-per-node=2 --mem=60G --cpus-per-task=16'
	}

	withLabel: bigmem {
		time = { 8.h *task.attempt}
		clusterOptions = '--job-name=nepal_B --account=nn9305k --partition=bigmem --mem-per-cpu=32000M'
	}

	cpus = 4  // standard
	time = { 2.h * task.attempt }

	withLabel: longtime {
		time = { 24.h * task.attempt }
	}
}


// setting the workflows directory
params.workflow_dir="./workflows"

// setting the use of conda environments
conda.enabled = true